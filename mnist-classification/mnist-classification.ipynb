{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3633fe27",
   "metadata": {},
   "source": [
    "## MNIST Digit Classification\n",
    "\n",
    "The MNIST dataset contains 70,000 grayscale images of handwritten digits (28×28 pixels each).  \n",
    "The task is to build a model that can automatically classify these digits into one of ten classes (0–9).\n",
    "\n",
    "Although MNIST is considered an introductory benchmark, the dataset still presents meaningful challenges:  \n",
    "handwriting varies widely in shape, thickness, orientation, and overall style.  \n",
    "A successful classifier must therefore learn useful representations from raw pixel values and generalise across diverse writing patterns.\n",
    "\n",
    "This project focuses on:\n",
    "\n",
    "1. Implementing baseline and improved neural network models for MNIST classification  \n",
    "   (a simple MLP and a convolutional model).\n",
    "2. Understanding how architectural choices influence learning behaviour and accuracy.\n",
    "3. Applying core deep-learning components such as activation functions, optimisers, and regularisation.\n",
    "4. Producing clear, reproducible training results suitable for inclusion in a portfolio or research application.\n",
    "\n",
    "The goal is to demonstrate a practical and principled approach to building image-classification models,  \n",
    "while highlighting the difference between fully-connected and convolutional architectures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e08055",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3abbe098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20ee6eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c69703",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # [0,255] -> [0,1]\n",
    "    transforms.Normalize((0.1307,), (0.3081,)) \n",
    "])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fda377b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000 Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    "    download=True\n",
    ")\n",
    "print(\"Train size:\", len(train_dataset), \"Test size:\", len(test_dataset))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0194d",
   "metadata": {},
   "source": [
    "Here I did $\\bf{NOT}$ normalise the tensors at the firsthand. Let's just see if it really matters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73f1ed",
   "metadata": {},
   "source": [
    "Then we define the training process in a reusable way for the convenience of further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db742ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, criterion, dataloader, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        \n",
    "        _, predicted = torch.max(outputs, dim=1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5c2f22dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, criterion, dataloader, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in dataloader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    \n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1c6d55",
   "metadata": {},
   "source": [
    "## REFERENCE:\n",
    "1. https://pytorch.org/\n",
    "2. https://blog.csdn.net/zdx2585503940/article/details/148641218\n",
    "3. https://zhuanlan.zhihu.com/p/1976326763652088525"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
